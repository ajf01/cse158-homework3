{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import string\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    for l in gzip.open(path, 'r+'):\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        try:\n",
    "            g = d['gameID']\n",
    "        except Exception as e:\n",
    "            g = None\n",
    "        yield u,g,d\n",
    "    \n",
    "def parseData(path):\n",
    "    for l in gzip.open(path, 'r+'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedT = list(parseData('train.json.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits dataset into train and validation sets\n",
    "train = []\n",
    "val = []\n",
    "for x in range(165000):\n",
    "    train.append(parsedT[x])\n",
    "for x in range(165000,175000):\n",
    "    val.append(parsedT[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates List For USER ITEM pair and a list for all unique games\n",
    "UIV = [(d['userID'],d['gameID'],1) for d in val]\n",
    "allGames = list(set([d['gameID'] for d in parsedT]))\n",
    "uniqV = {}\n",
    "\n",
    "#Loops through user item pair and creates dictionaries for each user and all games they have played\n",
    "for x in UIV:\n",
    "    if x[0] not in uniqV.keys():\n",
    "        uniqV[x[0]] = [x[1]]\n",
    "    else:\n",
    "        uniqV[x[0]].append(x[1])\n",
    "\n",
    "#Loops through rest of train data and adds other games users have played\n",
    "for x in train:\n",
    "    if x['userID'] in uniqV.keys():\n",
    "        uniqV[x['userID']].append(x['gameID'])\n",
    "        \n",
    "#Loops through each user in user item list and randomly samples game they have never played and appends to list\n",
    "for x in range(len(UIV)):\n",
    "    #Finds the games from all games that the user has never played\n",
    "    no_play = list(set(allGames) ^ set(uniqV[UIV[x][0]]))\n",
    "    \n",
    "    #Randomly samples a new game\n",
    "    new_game = np.random.choice(no_play,1)[0]\n",
    "    \n",
    "    #Checks to see if this game has been sampled before\n",
    "    if (UIV[x][0], new_game, 0) not in UIV:\n",
    "        #Appends new sample game as a game the user has not played yet\n",
    "        UIV.append((UIV[x][0], new_game, 0))\n",
    "        \n",
    "        #Appends sampled game to dictionary so as to say this game has now been selected do not select again\n",
    "        uniqV[UIV[x][0]].append(new_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameCount = defaultdict(int)\n",
    "totalPlayed = 0\n",
    "\n",
    "for x in train:\n",
    "    gameCount[x['gameID']] += 1\n",
    "    totalPlayed += 1\n",
    "\n",
    "mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPlayed/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The true values for the validation set\n",
    "truePlay = [d[2] for d in UIV]\n",
    "\n",
    "#The predicted value based on a 50th percentile threshold\n",
    "playPred = []\n",
    "for x in UIV:\n",
    "    if x[1] in return1:\n",
    "        playPred.append(1)\n",
    "    else:\n",
    "        playPred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.6806}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_ = np.logical_and(playPred, truePlay)\n",
    "FP_ = np.logical_and(playPred, np.logical_not(truePlay))\n",
    "TN_ = np.logical_and(np.logical_not(playPred), np.logical_not(truePlay))\n",
    "FN_ = np.logical_and(np.logical_not(playPred), truePlay)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "\n",
    "# accuracy\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "{'Accuracy':accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.6806, 0.636, 0.6069, 0.586, 0.57195, 0.5639, 0.5555, 0.5502, 0.54495]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomly choose values incrementing from the baseline of 2\n",
    "per = [1,2,3,4,5,6,7,8,9,10]\n",
    "acc = []\n",
    "for thresh in per:\n",
    "    return2 = set()\n",
    "    count2 = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count2 += ic\n",
    "        return2.add(i)\n",
    "        if count2 > totalPlayed/thresh: break\n",
    "\n",
    "    #The predicted value based on the xth percentile threshold\n",
    "    predImp = []\n",
    "    for x in UIV:\n",
    "        if x[1] in return2:\n",
    "            predImp.append(1)\n",
    "        else:\n",
    "            predImp.append(0)\n",
    "\n",
    "    #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "    TP_2 = np.logical_and(predImp, truePlay)\n",
    "    FP_2 = np.logical_and(predImp, np.logical_not(truePlay))\n",
    "    TN_2 = np.logical_and(np.logical_not(predImp), np.logical_not(truePlay))\n",
    "    FN_2 = np.logical_and(np.logical_not(predImp), truePlay)\n",
    "\n",
    "    #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "    TP2 = sum(TP_2)\n",
    "    FP2 = sum(FP_2)\n",
    "    TN2 = sum(TN_2)\n",
    "    FN2 = sum(FN_2)\n",
    "\n",
    "    # accuracy\n",
    "    acc.append((TP2 + TN2) / (TP2 + FP2 + TN2 + FN2))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6757, 0.6701, 0.6653, 0.6611, 0.65645, 0.65135, 0.64745, 0.6433, 0.6397]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saw that dividing by 3 gave the highest value so narrowed results between 2 and 3\n",
    "per = [2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9]\n",
    "acc = []\n",
    "for thresh in per:\n",
    "    return2 = set()\n",
    "    count2 = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count2 += ic\n",
    "        return2.add(i)\n",
    "        if count2 > totalPlayed/thresh: break\n",
    "\n",
    "    #The predicted value based on the xth percentile threshold\n",
    "    predImp = []\n",
    "    for x in UIV:\n",
    "        if x[1] in return2:\n",
    "            predImp.append(1)\n",
    "        else:\n",
    "            predImp.append(0)\n",
    "\n",
    "    #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "    TP_2 = np.logical_and(predImp, truePlay)\n",
    "    FP_2 = np.logical_and(predImp, np.logical_not(truePlay))\n",
    "    TN_2 = np.logical_and(np.logical_not(predImp), np.logical_not(truePlay))\n",
    "    FN_2 = np.logical_and(np.logical_not(predImp), truePlay)\n",
    "\n",
    "    #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "    TP2 = sum(TP_2)\n",
    "    FP2 = sum(FP_2)\n",
    "    TN2 = sum(TN_2)\n",
    "    FN2 = sum(FN_2)\n",
    "\n",
    "    # accuracy\n",
    "    acc.append((TP2 + TN2) / (TP2 + FP2 + TN2 + FN2))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.54495, 0.586, 0.6249, 0.65645, 0.6806, 0.6975, 0.70115, 0.6818, 0.6264]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tried multiplying be percentages instead\n",
    "per = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "acc = []\n",
    "for thresh in per:\n",
    "    return2 = set()\n",
    "    count2 = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count2 += ic\n",
    "        return2.add(i)\n",
    "        if count2 > totalPlayed*thresh: break\n",
    "\n",
    "    #The predicted value based on the xth percentile threshold\n",
    "    predImp = []\n",
    "    for x in UIV:\n",
    "        if x[1] in return2:\n",
    "            predImp.append(1)\n",
    "        else:\n",
    "            predImp.append(0)\n",
    "\n",
    "    #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "    TP_2 = np.logical_and(predImp, truePlay)\n",
    "    FP_2 = np.logical_and(predImp, np.logical_not(truePlay))\n",
    "    TN_2 = np.logical_and(np.logical_not(predImp), np.logical_not(truePlay))\n",
    "    FN_2 = np.logical_and(np.logical_not(predImp), truePlay)\n",
    "\n",
    "    #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "    TP2 = sum(TP_2)\n",
    "    FP2 = sum(FP_2)\n",
    "    TN2 = sum(TN_2)\n",
    "    FN2 = sum(FN_2)\n",
    "\n",
    "    # accuracy\n",
    "    acc.append((TP2 + TN2) / (TP2 + FP2 + TN2 + FN2))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6987, 0.6989, 0.7006, 0.7002, 0.70115, 0.7021, 0.703, 0.70245, 0.70235]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tightened the range\n",
    "per = [0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69]\n",
    "acc = []\n",
    "for thresh in per:\n",
    "    return2 = set()\n",
    "    count2 = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count2 += ic\n",
    "        return2.add(i)\n",
    "        if count2 > totalPlayed*thresh: break\n",
    "\n",
    "    #The predicted value based on the xth percentile threshold\n",
    "    predImp = []\n",
    "    for x in UIV:\n",
    "        if x[1] in return2:\n",
    "            predImp.append(1)\n",
    "        else:\n",
    "            predImp.append(0)\n",
    "\n",
    "    #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "    TP_2 = np.logical_and(predImp, truePlay)\n",
    "    FP_2 = np.logical_and(predImp, np.logical_not(truePlay))\n",
    "    TN_2 = np.logical_and(np.logical_not(predImp), np.logical_not(truePlay))\n",
    "    FN_2 = np.logical_and(np.logical_not(predImp), truePlay)\n",
    "\n",
    "    #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "    TP2 = sum(TP_2)\n",
    "    FP2 = sum(FP_2)\n",
    "    TN2 = sum(TN_2)\n",
    "    FN2 = sum(FN_2)\n",
    "\n",
    "    # accuracy\n",
    "    acc.append((TP2 + TN2) / (TP2 + FP2 + TN2 + FN2))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Best threshold is totalPlayed*0.7': 0.70115}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Best threshold is totalPlayed*0.7': 0.70115}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(user1,user2):\n",
    "    user1 = set(user1)\n",
    "    user2 = set(user2)\n",
    "    numer = len(user1.intersection(user2))\n",
    "    denom = len(user1.union(user2))\n",
    "    if denom > 0:\n",
    "        return numer/denom\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def findUsers(id):\n",
    "    return [d['userID'] for d in train if d['gameID'] == id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates list unique userID and two dictionaries store validation users and the games they played and all games\n",
    "#and users that have played them\n",
    "valID = set([d['userID'] for d in val])\n",
    "valTrainPlay = {}\n",
    "userGames = {}\n",
    "for x in valID:\n",
    "    valTrainPlay[x] = []\n",
    "for x in train:\n",
    "    if x['userID'] in valTrainPlay.keys():\n",
    "        valTrainPlay[x['userID']].append(x['gameID'])\n",
    "for x in allGames:\n",
    "    userGames[x] = findUsers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5191, 0.60805, 0.67445, 0.6458, 0.58875, 0.55205, 0.53385, 0.5181, 0.50835]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tried 0.1 and realized should choose values between 0 and 0.1\n",
    "base = [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09]\n",
    "simil = []\n",
    "for thresh in base:\n",
    "    jPred = []\n",
    "    for x in UIV:\n",
    "        similarities = []\n",
    "        #Finds all users that have played g\n",
    "        g = userGames[x[1]]\n",
    "        for y in valTrainPlay[x[0]]:\n",
    "            #Finds all users that have played g' and computes Jaccard similarity\n",
    "            gPrime = userGames[y]\n",
    "            similarities.append(Jaccard(g,gPrime))\n",
    "        #Make prediction based on whether Jaccard similarity is greater than threshold\n",
    "        if max(similarities) >= thresh:\n",
    "            jPred.append(1)\n",
    "        else:\n",
    "            jPred.append(0)\n",
    "    #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "    TP_J = np.logical_and(jPred, truePlay)\n",
    "    FP_J = np.logical_and(jPred, np.logical_not(truePlay))\n",
    "    TN_J = np.logical_and(np.logical_not(jPred), np.logical_not(truePlay))\n",
    "    FN_J = np.logical_and(np.logical_not(jPred), truePlay)\n",
    "\n",
    "    #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "    TPJ = sum(TP_J)\n",
    "    FPJ = sum(FP_J)\n",
    "    TNJ = sum(TN_J)\n",
    "    FNJ = sum(FN_J)\n",
    "\n",
    "    simil.append((TPJ + TNJ) / (TPJ + FPJ + TNJ + FNJ))\n",
    "simil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6747, 0.67405, 0.6745, 0.6719, 0.67, 0.66625, 0.6613, 0.65665, 0.65125]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saw the best accuracy around 0.03 and 0.04\n",
    "base = [0.031,0.032,0.033,0.034,0.035,0.036,0.037,0.038,0.039]\n",
    "simil = []\n",
    "for thresh in base:\n",
    "    jPred = []\n",
    "    for x in UIV:\n",
    "        similarities = []\n",
    "        #Finds all users that have played g\n",
    "        g = userGames[x[1]]\n",
    "        for y in valTrainPlay[x[0]]:\n",
    "            #Finds all users that have played g' and computes Jaccard similarity\n",
    "            gPrime = userGames[y]\n",
    "            similarities.append(Jaccard(g,gPrime))\n",
    "        #Make prediction based on whether Jaccard similarity is greater than threshold\n",
    "        if max(similarities) >= thresh:\n",
    "            jPred.append(1)\n",
    "        else:\n",
    "            jPred.append(0)\n",
    "    #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "    TP_J = np.logical_and(jPred, truePlay)\n",
    "    FP_J = np.logical_and(jPred, np.logical_not(truePlay))\n",
    "    TN_J = np.logical_and(np.logical_not(jPred), np.logical_not(truePlay))\n",
    "    FN_J = np.logical_and(np.logical_not(jPred), truePlay)\n",
    "\n",
    "    #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "    TPJ = sum(TP_J)\n",
    "    FPJ = sum(FP_J)\n",
    "    TNJ = sum(TN_J)\n",
    "    FNJ = sum(FN_J)\n",
    "\n",
    "    simil.append((TPJ + TNJ) / (TPJ + FPJ + TNJ + FNJ))\n",
    "simil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Best threshold is >= 0.031': 0.6747}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Best threshold is >= 0.031': 0.6747}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.70115}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cPred = []\n",
    "return3 = set()\n",
    "count3 = 0\n",
    "for ic, i in mostPopular:\n",
    "    count3 += ic\n",
    "    return3.add(i)\n",
    "    if count3 > totalPlayed*0.7: break\n",
    "for x in UIV:\n",
    "    similarities = []\n",
    "    #Finds all users that have played g\n",
    "    gC = userGames[x[1]]\n",
    "    for y in valTrainPlay[x[0]]:\n",
    "        #Finds all users that have played g' and computes Jaccard similarity\n",
    "        gCPrime = userGames[y]\n",
    "        similarities.append(Jaccard(gC,gCPrime))\n",
    "    #Make prediction based on Jaccard threshold and popularity threshold\n",
    "    if (max(similarities) >= 0.031) and (x[1] in return3):\n",
    "        cPred.append(1)\n",
    "    elif (max(similarities) < 0.031) and (x[1] in return3):\n",
    "        cPred.append(1)\n",
    "    else:\n",
    "        cPred.append(0)\n",
    "\n",
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_C = np.logical_and(cPred, truePlay)\n",
    "FP_C = np.logical_and(cPred, np.logical_not(truePlay))\n",
    "TN_C = np.logical_and(np.logical_not(cPred), np.logical_not(truePlay))\n",
    "FN_C = np.logical_and(np.logical_not(cPred), truePlay)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TPC = sum(TP_C)\n",
    "FPC = sum(FP_C)\n",
    "TNC = sum(TN_C)\n",
    "FNC = sum(FN_C)\n",
    "\n",
    "{'Accuracy':(TPC + TNC) / (TPC + FPC + TNC + FNC)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Username: Anthony Fong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Played.txt\", 'w')\n",
    "for l in open(\"pairs_Played.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split('-')\n",
    "    similarities = []\n",
    "    #Finds all users that have played g\n",
    "    if (g in userGames.keys()) and (u in valTrainPlay.keys()):\n",
    "        gC = userGames[g]\n",
    "        for y in valTrainPlay[u]:\n",
    "            #Finds all users that have played g' and computes Jaccard similarity\n",
    "            gCPrime = userGames[y]\n",
    "            similarities.append(Jaccard(gC,gCPrime))\n",
    "    if len(similarities) == 0:\n",
    "        greatBig = 0\n",
    "    if len(similarities) != 0:\n",
    "        greatBig = max(similarities)\n",
    "    if greatBig >= 0.031 and g in return3:\n",
    "        predictions.write(u + '-' + g + \",1\\n\")\n",
    "    elif greatBig < 0.031 and g in return3:\n",
    "        predictions.write(u + '-' + g + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + g + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedC = list(parseData('train_Category.json.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits dataset into train and validation splits\n",
    "trainC = []\n",
    "valC = []\n",
    "for x in range(165000):\n",
    "    trainC.append(parsedC[x])\n",
    "for x in range(165000,175000):\n",
    "    valC.append(parsedC[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(544597, 'the'),\n",
       " (317620, 'and'),\n",
       " (305414, 'a'),\n",
       " (291882, 'to'),\n",
       " (245359, 'game'),\n",
       " (227234, 'of'),\n",
       " (208417, 'is'),\n",
       " (200633, 'you'),\n",
       " (195953, 'i'),\n",
       " (190966, 'it')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Just take the most popular words...\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in trainC:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "counts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7\n",
    "# Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    return feat\n",
    "\n",
    "#Creates feature vector using feature function and creates list of genreID values\n",
    "bow = [feature(d) for d in trainC]\n",
    "genreID = [d['genreID'] for d in trainC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates validation x and y sets for prediction\n",
    "x_val = [feature(d) for d in valC]\n",
    "y_val = [d['genreID'] for d in valC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Logistic Regressor and trains on train feature vector and genreID to predict on validation set\n",
    "clf = LogisticRegression(max_iter=5000).fit(bow,genreID)\n",
    "bowPred = clf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.6922}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_Bag = np.logical_and(bowPred, y_val)\n",
    "FP_Bag = np.logical_and(bowPred, np.logical_not(y_val))\n",
    "TN_Bag = np.logical_and(np.logical_not(bowPred), np.logical_not(y_val))\n",
    "FN_Bag = np.logical_and(np.logical_not(bowPred), y_val)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TPBag = sum(TP_Bag)\n",
    "FPBag = sum(FP_Bag)\n",
    "TNBag = sum(TN_Bag)\n",
    "FNBag = sum(FN_Bag)\n",
    "\n",
    "{'Accuracy': (TPBag + TNBag) / (TPBag + FPBag + TNBag + FNBag)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Username: Anthony Fong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMod(datum,much):\n",
    "    feat = [0]*len(words[:much])\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words[:much]:\n",
    "            feat[wordId2[w]] += 1\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-06: [0.5533, 0.5533, 0.5533],\n",
       " 1e-05: [0.5556, 0.5564, 0.557],\n",
       " 0.0001: [0.5695, 0.5792, 0.5822],\n",
       " 0.001: [0.595, 0.6248, 0.637]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tries different C and size values and stores it in dictionary\n",
    "c = [0.000001,0.00001,0.0001,0.001]\n",
    "size = [250,500,750]\n",
    "grid = {}\n",
    "for x in c:\n",
    "    curr = []\n",
    "    for y in size:\n",
    "        wordId2 = dict(zip(words[:y], range(len(words[:y]))))\n",
    "        wordSet2 = set(words[:y])\n",
    "        bow2 = [featureMod(d,y) for d in trainC]\n",
    "        x_val2 = [featureMod(d,y) for d in valC]\n",
    "        clf2 = LogisticRegression(C=x,max_iter=1000).fit(bow2,genreID)\n",
    "        bowPred2 = clf2.predict(x_val2)\n",
    "        \n",
    "        #Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "        TP_Bag2 = np.logical_and(bowPred2, y_val)\n",
    "        FP_Bag2 = np.logical_and(bowPred2, np.logical_not(y_val))\n",
    "        TN_Bag2 = np.logical_and(np.logical_not(bowPred2), np.logical_not(y_val))\n",
    "        FN_Bag2 = np.logical_and(np.logical_not(bowPred2), y_val)\n",
    "\n",
    "        #Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "        TPBag2 = sum(TP_Bag2)\n",
    "        FPBag2 = sum(FP_Bag2)\n",
    "        TNBag2 = sum(TN_Bag2)\n",
    "        FNBag2 = sum(FN_Bag2)\n",
    "\n",
    "        curr.append((TPBag2 + TNBag2) / (TPBag2 + FPBag2 + TNBag2 + FNBag2))\n",
    "    grid[x] = curr\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7154}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates Logistic Regressor and trains on train feature vector and genreID to predict on validation set\n",
    "words2 = [x[1] for x in counts[:1500]]\n",
    "wordId2 = dict(zip(words2, range(len(words2))))\n",
    "wordSet2 = set(words2)\n",
    "def feature1500(datum):\n",
    "    feat = [0]*len(words2)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words2:\n",
    "            feat[wordId2[w]] += 1\n",
    "    return feat\n",
    "bow2 = [feature1500(d) for d in trainC]\n",
    "x_val2 = [feature1500(d) for d in valC]\n",
    "clfBest = LogisticRegression(max_iter=5000).fit(bow2,genreID)\n",
    "bowPredBest = clfBest.predict(x_val2)\n",
    "\n",
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_Bag2 = np.logical_and(bowPredBest, y_val)\n",
    "FP_Bag2 = np.logical_and(bowPredBest, np.logical_not(y_val))\n",
    "TN_Bag2 = np.logical_and(np.logical_not(bowPredBest), np.logical_not(y_val))\n",
    "FN_Bag2 = np.logical_and(np.logical_not(bowPredBest), y_val)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TPBag2 = sum(TP_Bag2)\n",
    "FPBag2 = sum(FP_Bag2)\n",
    "TNBag2 = sum(TN_Bag2)\n",
    "FNBag2 = sum(FN_Bag2)\n",
    "\n",
    "{'Accuracy': (TPBag2 + TNBag2) / (TPBag2 + FPBag2 + TNBag2 + FNBag2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedCat = list(parseData('test_Category.json.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = [feature1500(d) for d in parsedCat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = clfBest.predict(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Category prediction baseline: Just consider some of the most common words from each category\n",
    "hold = 0\n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "for l in open(\"pairs_Category.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,r = l.strip().split('-')\n",
    "    predictions.write(u + '-' + r + \",\" + str(cat[hold]) + \"\\n\")\n",
    "    hold += 1\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
